{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HurdleDMR\n",
    "\n",
    "HurdleDMR.jl is a Julia implementation of the Hurdle Distributed Multiple Regression (HDMR), as described in:\n",
    "\n",
    "Kelly, Bryan, Asaf Manela, and Alan Moreira (2018). Text Selection. [Working paper](http://apps.olin.wustl.edu/faculty/manela/kmm/textselection/).\n",
    "\n",
    "It includes a Julia implementation of the Distributed Multinomial Regression (DMR) model of [Taddy (2015)](https://arxiv.org/abs/1311.6139).\n",
    "\n",
    "This tutorial explains how to use this package.\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Install Julia\n",
    "\n",
    "First, install Julia itself. The easiest way to do that is from the download site https://julialang.org/downloads/. An alternative is to install JuliaPro from https://juliacomputing.com\n",
    "\n",
    "Once installed, open julia in a terminal (or in Atom), press `]` to activate package manager and add the following packages:\n",
    "```\n",
    "pkg> add HurdleDMR\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add parallel workers and make package available to workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs(Sys.CPU_THREADS-2)\n",
    "import HurdleDMR; @everywhere using HurdleDMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Data\n",
    "\n",
    "Setup your data into an n-by-p covars matrix, and a (sparse) n-by-d counts matrix. Here we generate some random data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if not installed, install following package with \n",
    "```\n",
    "pkg> add CSV GLM DataFrames Distributions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/root/.julia/compiled/v1.0/CSV/HHBkp.ji for CSV [336ed68f-0bac-5ca0-87d4-7b16caf5d00b]\n",
      "└ @ Base loading.jl:1190\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>vy</th><th>v1</th><th>v2</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>100 rows × 3 columns</p><tr><th>1</th><td>0.693073</td><td>0.877116</td><td>0.401554</td></tr><tr><th>2</th><td>0.938163</td><td>0.737491</td><td>0.997271</td></tr><tr><th>3</th><td>0.755878</td><td>0.743268</td><td>0.595892</td></tr><tr><th>4</th><td>0.191058</td><td>0.296443</td><td>0.30533</td></tr><tr><th>5</th><td>0.00753542</td><td>0.360474</td><td>0.335553</td></tr><tr><th>6</th><td>0.410974</td><td>0.773871</td><td>0.657641</td></tr><tr><th>7</th><td>0.279942</td><td>0.154284</td><td>0.321258</td></tr><tr><th>8</th><td>0.208454</td><td>0.849653</td><td>0.22147</td></tr><tr><th>9</th><td>0.639872</td><td>0.926706</td><td>0.444675</td></tr><tr><th>10</th><td>0.269132</td><td>0.83785</td><td>0.0137366</td></tr><tr><th>11</th><td>0.704959</td><td>0.120137</td><td>0.401541</td></tr><tr><th>12</th><td>0.820248</td><td>0.379542</td><td>0.704862</td></tr><tr><th>13</th><td>0.752849</td><td>0.745383</td><td>0.907775</td></tr><tr><th>14</th><td>0.634401</td><td>0.383528</td><td>0.276991</td></tr><tr><th>15</th><td>0.370604</td><td>0.595542</td><td>0.0999965</td></tr><tr><th>16</th><td>0.400454</td><td>0.596132</td><td>0.00424357</td></tr><tr><th>17</th><td>0.331037</td><td>0.777271</td><td>0.963936</td></tr><tr><th>18</th><td>0.109256</td><td>0.45404</td><td>0.873842</td></tr><tr><th>19</th><td>0.0384627</td><td>0.358023</td><td>0.369017</td></tr><tr><th>20</th><td>0.655115</td><td>0.984853</td><td>0.284056</td></tr><tr><th>21</th><td>0.961148</td><td>0.425115</td><td>0.836061</td></tr><tr><th>22</th><td>0.313693</td><td>0.631212</td><td>0.33691</td></tr><tr><th>23</th><td>0.468663</td><td>0.203475</td><td>0.0895971</td></tr><tr><th>24</th><td>0.130995</td><td>0.416474</td><td>0.25323</td></tr><tr><th>25</th><td>0.510355</td><td>0.418123</td><td>0.542134</td></tr><tr><th>26</th><td>0.763879</td><td>0.501635</td><td>0.257008</td></tr><tr><th>27</th><td>0.139297</td><td>0.337539</td><td>0.143543</td></tr><tr><th>28</th><td>0.315356</td><td>0.838806</td><td>0.0502037</td></tr><tr><th>29</th><td>0.359166</td><td>0.992776</td><td>0.882517</td></tr><tr><th>30</th><td>0.511267</td><td>0.983282</td><td>0.976795</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& vy & v1 & v2\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.693073 & 0.877116 & 0.401554 \\\\\n",
       "\t2 & 0.938163 & 0.737491 & 0.997271 \\\\\n",
       "\t3 & 0.755878 & 0.743268 & 0.595892 \\\\\n",
       "\t4 & 0.191058 & 0.296443 & 0.30533 \\\\\n",
       "\t5 & 0.00753542 & 0.360474 & 0.335553 \\\\\n",
       "\t6 & 0.410974 & 0.773871 & 0.657641 \\\\\n",
       "\t7 & 0.279942 & 0.154284 & 0.321258 \\\\\n",
       "\t8 & 0.208454 & 0.849653 & 0.22147 \\\\\n",
       "\t9 & 0.639872 & 0.926706 & 0.444675 \\\\\n",
       "\t10 & 0.269132 & 0.83785 & 0.0137366 \\\\\n",
       "\t11 & 0.704959 & 0.120137 & 0.401541 \\\\\n",
       "\t12 & 0.820248 & 0.379542 & 0.704862 \\\\\n",
       "\t13 & 0.752849 & 0.745383 & 0.907775 \\\\\n",
       "\t14 & 0.634401 & 0.383528 & 0.276991 \\\\\n",
       "\t15 & 0.370604 & 0.595542 & 0.0999965 \\\\\n",
       "\t16 & 0.400454 & 0.596132 & 0.00424357 \\\\\n",
       "\t17 & 0.331037 & 0.777271 & 0.963936 \\\\\n",
       "\t18 & 0.109256 & 0.45404 & 0.873842 \\\\\n",
       "\t19 & 0.0384627 & 0.358023 & 0.369017 \\\\\n",
       "\t20 & 0.655115 & 0.984853 & 0.284056 \\\\\n",
       "\t21 & 0.961148 & 0.425115 & 0.836061 \\\\\n",
       "\t22 & 0.313693 & 0.631212 & 0.33691 \\\\\n",
       "\t23 & 0.468663 & 0.203475 & 0.0895971 \\\\\n",
       "\t24 & 0.130995 & 0.416474 & 0.25323 \\\\\n",
       "\t25 & 0.510355 & 0.418123 & 0.542134 \\\\\n",
       "\t26 & 0.763879 & 0.501635 & 0.257008 \\\\\n",
       "\t27 & 0.139297 & 0.337539 & 0.143543 \\\\\n",
       "\t28 & 0.315356 & 0.838806 & 0.0502037 \\\\\n",
       "\t29 & 0.359166 & 0.992776 & 0.882517 \\\\\n",
       "\t30 & 0.511267 & 0.983282 & 0.976795 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "100×3 DataFrame\n",
       "│ Row │ vy         │ v1        │ v2        │\n",
       "│     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │\n",
       "├─────┼────────────┼───────────┼───────────┤\n",
       "│ 1   │ 0.693073   │ 0.877116  │ 0.401554  │\n",
       "│ 2   │ 0.938163   │ 0.737491  │ 0.997271  │\n",
       "│ 3   │ 0.755878   │ 0.743268  │ 0.595892  │\n",
       "│ 4   │ 0.191058   │ 0.296443  │ 0.30533   │\n",
       "│ 5   │ 0.00753542 │ 0.360474  │ 0.335553  │\n",
       "│ 6   │ 0.410974   │ 0.773871  │ 0.657641  │\n",
       "│ 7   │ 0.279942   │ 0.154284  │ 0.321258  │\n",
       "│ 8   │ 0.208454   │ 0.849653  │ 0.22147   │\n",
       "│ 9   │ 0.639872   │ 0.926706  │ 0.444675  │\n",
       "│ 10  │ 0.269132   │ 0.83785   │ 0.0137366 │\n",
       "⋮\n",
       "│ 90  │ 0.406825   │ 0.596095  │ 0.917259  │\n",
       "│ 91  │ 0.155235   │ 0.843106  │ 0.624239  │\n",
       "│ 92  │ 0.392799   │ 0.188386  │ 0.370373  │\n",
       "│ 93  │ 0.140967   │ 0.231702  │ 0.643646  │\n",
       "│ 94  │ 0.949803   │ 0.193669  │ 0.6456    │\n",
       "│ 95  │ 0.545791   │ 0.0684737 │ 0.214744  │\n",
       "│ 96  │ 0.873547   │ 0.340041  │ 0.387132  │\n",
       "│ 97  │ 0.268384   │ 0.638205  │ 0.0480452 │\n",
       "│ 98  │ 0.335241   │ 0.45505   │ 0.414783  │\n",
       "│ 99  │ 0.0528473  │ 0.295635  │ 0.259848  │\n",
       "│ 100 │ 0.561838   │ 0.815154  │ 0.210454  │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV, GLM, DataFrames, Distributions, Random, LinearAlgebra, SparseArrays\n",
    "n = 100\n",
    "p = 3\n",
    "d = 4\n",
    "\n",
    "Random.seed!(13)\n",
    "m = 1 .+ rand(Poisson(5),n)\n",
    "covars = rand(n,p)\n",
    "ηfn(vi) = exp.([0 + i*sum(vi) for i=1:d])\n",
    "q = [ηfn(covars[i,:]) for i=1:n]\n",
    "rmul!.(q,ones(n)./sum.(q))\n",
    "counts = convert(SparseMatrixCSC{Float64,Int},hcat(broadcast((qi,mi)->rand(Multinomial(mi, qi)),q,m)...)')\n",
    "covarsdf = DataFrame(covars,[:vy, :v1, :v2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Multinomial Regression (DMR)\n",
    "\n",
    "The Distributed Multinomial Regression (DMR) model of Taddy (2015) is a highly scalable\n",
    "approximation to the Multinomial using distributed (independent, parallel)\n",
    "Poisson regressions, one for each of the d categories (columns) of a large `counts` matrix,\n",
    "on the `covars`.\n",
    "\n",
    "To fit a DMR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: fitting 100 observations on 4 categories, 3 covariates \n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/dmr.jl:272\n",
      "┌ Info: distributed poisson run on local cluster with 2 nodes\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/dmr.jl:281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DMRCoefs([-0.277378 -1.10612 -1.18168 -0.746987; -3.94502 -1.7695 -0.387265 0.355981; -2.83456 -1.82878 0.0 0.212385; -2.72819 -0.983448 -0.346102 0.247442], true, 100, 4, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = dmr(covars, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or with a dataframe and formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: fitting 100 observations on 4 categories, 3 covariates \n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/dmr.jl:272\n",
      "┌ Info: distributed poisson run on local cluster with 2 nodes\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/dmr.jl:281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DMRCoefs([-0.277378 -1.10612 -1.18168 -0.746987; -3.94502 -1.7695 -0.387265 0.355981; -2.83456 -1.82878 0.0 0.212385; -2.72819 -0.983448 -0.346102 0.247442], true, 100, 4, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = @model(c ~ vy + v1 + v2)\n",
    "m = fit(DMR, mf, covarsdf, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in either case we can get the coefficients matrix for each variable + intercept as usual with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 SharedArrays.SharedArray{Float64,2}:\n",
       " -0.277378  -1.10612   -1.18168   -0.746987\n",
       " -3.94502   -1.7695    -0.387265   0.355981\n",
       " -2.83456   -1.82878    0.0        0.212385\n",
       " -2.72819   -0.983448  -0.346102   0.247442"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default we only return the AICc maximizing coefficients.\n",
    "To also get back the entire regulatrization paths, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: fitting 100 observations on 4 categories, 3 covariates \n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/dmr.jl:318\n",
      "┌ Info: distributed poisson run on remote cluster with 2 nodes\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/dmr.jl:336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DMRPaths(Union{Missing, GammaLassoPath}[Poisson GammaLassoPath (56) solutions for 4 predictors in 330 iterations):\n",
       "                λ   pct_dev ncoefs\n",
       " [1]     0.108369       0.0      0\n",
       " [2]     0.098742 0.0275025      1\n",
       " [3]      0.08997 0.0509363      1\n",
       " [4]    0.0819773 0.0793996      2\n",
       " [5]    0.0746947  0.112825      3\n",
       " [6]     0.068059  0.148402      3\n",
       " [7]    0.0620129  0.179008      3\n",
       " [8]    0.0565038    0.2054      3\n",
       " [9]    0.0514842  0.228196      3\n",
       "[10]    0.0469105  0.247908      3\n",
       "[11]    0.0427431  0.264961      3\n",
       "[12]    0.0389459  0.279718      3\n",
       "[13]     0.035486  0.292484      3\n",
       "[14]    0.0323336  0.303522      3\n",
       "[15]    0.0294611   0.31306      3\n",
       "[16]    0.0268439  0.321293      3\n",
       "[17]    0.0244591  0.328392      3\n",
       "[18]    0.0222863  0.334505      3\n",
       "[19]    0.0203064  0.339762      3\n",
       "[20]    0.0185024  0.344276      3\n",
       "[21]    0.0168587  0.348147      3\n",
       "[22]    0.0153611  0.351461      3\n",
       "[23]    0.0139964  0.354294      3\n",
       "[24]     0.012753  0.356711      3\n",
       "[25]    0.0116201  0.358771      3\n",
       "[26]    0.0105878  0.360524      3\n",
       "[27]   0.00964719  0.362013      3\n",
       "[28]   0.00879016  0.363277      3\n",
       "[29]   0.00800927  0.364347      3\n",
       "[30]   0.00729775  0.365253      3\n",
       "[31]   0.00664944  0.366018      3\n",
       "[32]   0.00605872  0.366664      3\n",
       "[33]   0.00552048  0.367208      3\n",
       "[34]   0.00503005  0.367667      3\n",
       "[35]    0.0045832  0.368052      3\n",
       "[36]   0.00417604  0.368376      3\n",
       "[37]   0.00380505  0.368648      3\n",
       "[38]   0.00346702  0.368876      3\n",
       "[39]   0.00315902  0.369068      3\n",
       "[40]   0.00287838  0.369228      3\n",
       "[41]   0.00262267  0.369362      3\n",
       "[42]   0.00238968  0.369474      3\n",
       "[43]   0.00217739  0.369568      3\n",
       "[44]   0.00198396  0.369646      3\n",
       "[45]   0.00180771  0.369711      3\n",
       "[46]   0.00164712  0.369766      3\n",
       "[47]   0.00150079  0.369811      3\n",
       "[48]   0.00136746  0.369849      3\n",
       "[49]   0.00124598  0.369881      3\n",
       "[50]   0.00113529  0.369907      3\n",
       "[51]   0.00103444  0.369929      3\n",
       "[52]   0.00094254  0.369948      3\n",
       "[53]  0.000858808  0.369963      3\n",
       "[54]  0.000782513  0.369975      3\n",
       "[55]  0.000712997  0.369986      3\n",
       "[56]  0.000649656  0.369995      3\n",
       ", Poisson GammaLassoPath (48) solutions for 4 predictors in 242 iterations):\n",
       "               λ   pct_dev ncoefs\n",
       " [1]    0.130638       0.0      0\n",
       " [2]    0.119032 0.0262986      2\n",
       " [3]    0.108458 0.0497641      2\n",
       " [4]   0.0988228 0.0695382      2\n",
       " [5]   0.0900437  0.088271      3\n",
       " [6]   0.0820444  0.105895      3\n",
       " [7]   0.0747558  0.120782      3\n",
       " [8]   0.0681147  0.133357      3\n",
       " [9]   0.0620636  0.143978      3\n",
       "[10]     0.05655  0.152946      3\n",
       "[11]   0.0515263  0.160513      3\n",
       "[12]   0.0469488  0.166898      3\n",
       "[13]    0.042778  0.172277      3\n",
       "[14]   0.0389778  0.176809      3\n",
       "[15]   0.0355151  0.180623      3\n",
       "[16]     0.03236  0.183831      3\n",
       "[17]   0.0294852  0.186527      3\n",
       "[18]   0.0268659  0.188791      3\n",
       "[19]   0.0244792  0.190691      3\n",
       "[20]   0.0223045  0.192285      3\n",
       "[21]    0.020323  0.193621      3\n",
       "[22]   0.0185176  0.194739      3\n",
       "[23]   0.0168725  0.195676      3\n",
       "[24]   0.0153736  0.196459      3\n",
       "[25]   0.0140079  0.197114      3\n",
       "[26]   0.0127635  0.197661      3\n",
       "[27]   0.0116296  0.198118      3\n",
       "[28]   0.0105964    0.1985      3\n",
       "[29]  0.00965509  0.198818      3\n",
       "[30]  0.00879736  0.199084      3\n",
       "[31]  0.00801582  0.199305      3\n",
       "[32]  0.00730372   0.19949      3\n",
       "[33]  0.00665488  0.199643      3\n",
       "[34]  0.00606368  0.199771      3\n",
       "[35]    0.005525  0.199878      3\n",
       "[36]  0.00503417  0.199967      3\n",
       "[37]  0.00458695  0.200041      3\n",
       "[38]  0.00417946  0.200102      3\n",
       "[39]  0.00380817  0.200154      3\n",
       "[40]  0.00346986  0.200196      3\n",
       "[41]  0.00316161  0.200231      3\n",
       "[42]  0.00288074  0.200261      3\n",
       "[43]  0.00262482  0.200285      3\n",
       "[44]  0.00239164  0.200306      3\n",
       "[45]  0.00217917  0.200323      3\n",
       "[46]  0.00198558  0.200337      3\n",
       "[47]  0.00180919  0.200348      3\n",
       "[48]  0.00164846  0.200358      3\n",
       ", Poisson GammaLassoPath (44) solutions for 4 predictors in 218 iterations):\n",
       "               λ   pct_dev ncoefs\n",
       " [1]     0.23463       0.0      0\n",
       " [2]    0.213786 0.0129647      2\n",
       " [3]    0.194794 0.0239732      2\n",
       " [4]    0.177489 0.0331495      2\n",
       " [5]    0.161721 0.0407988      2\n",
       " [6]    0.147354 0.0471745      2\n",
       " [7]    0.134264 0.0524878      2\n",
       " [8]    0.122336 0.0569149      2\n",
       " [9]    0.111468 0.0606031      2\n",
       "[10]    0.101566 0.0636751      2\n",
       "[11]   0.0925429 0.0662334      2\n",
       "[12]   0.0843216 0.0683634      2\n",
       "[13]   0.0768307 0.0701365      2\n",
       "[14]   0.0700053 0.0720438      3\n",
       "[15]   0.0637862 0.0738808      3\n",
       "[16]   0.0581196 0.0754093      3\n",
       "[17]   0.0529564 0.0766811      3\n",
       "[18]   0.0482519 0.0777391      3\n",
       "[19]   0.0439654  0.078619      3\n",
       "[20]   0.0400596 0.0793508      3\n",
       "[21]   0.0365008 0.0799593      3\n",
       "[22]   0.0332582 0.0804653      3\n",
       "[23]   0.0303036 0.0808859      3\n",
       "[24]   0.0276115 0.0812355      3\n",
       "[25]   0.0251586 0.0815261      3\n",
       "[26]   0.0229236 0.0817676      3\n",
       "[27]   0.0208871 0.0819683      3\n",
       "[28]   0.0190316  0.082135      3\n",
       "[29]   0.0173408 0.0822736      3\n",
       "[30]   0.0158003 0.0823887      3\n",
       "[31]   0.0143967 0.0824843      3\n",
       "[32]   0.0131177 0.0825638      3\n",
       "[33]   0.0119524 0.0826298      3\n",
       "[34]   0.0108906 0.0826846      3\n",
       "[35]  0.00992307 0.0827301      3\n",
       "[36]  0.00904153 0.0827679      3\n",
       "[37]  0.00823831 0.0827994      3\n",
       "[38]  0.00750644 0.0828254      3\n",
       "[39]  0.00683959 0.0828471      3\n",
       "[40]  0.00623198 0.0828651      3\n",
       "[41]  0.00567835   0.08288      3\n",
       "[42]   0.0051739 0.0828924      3\n",
       "[43]  0.00471426 0.0829028      3\n",
       "[44]  0.00429546 0.0829113      3\n",
       ", Poisson GammaLassoPath (49) solutions for 4 predictors in 231 iterations):\n",
       "               λ   pct_dev ncoefs\n",
       " [1]    0.471659       0.0      0\n",
       " [2]    0.429758  0.023192      1\n",
       " [3]     0.39158 0.0526047      2\n",
       " [4]    0.356793 0.0795194      2\n",
       " [5]    0.325096  0.101828      2\n",
       " [6]    0.296216  0.120322      2\n",
       " [7]    0.269901  0.140525      3\n",
       " [8]    0.245923  0.159758      3\n",
       " [9]    0.224076  0.175704      3\n",
       "[10]     0.20417  0.188926      3\n",
       "[11]    0.186032  0.199892      3\n",
       "[12]    0.169505  0.208987      3\n",
       "[13]    0.154447  0.216532      3\n",
       "[14]    0.140726  0.222791      3\n",
       "[15]    0.128225  0.227984      3\n",
       "[16]    0.116834  0.232293      3\n",
       "[17]    0.106454  0.235868      3\n",
       "[18]   0.0969973  0.238835      3\n",
       "[19]   0.0883803  0.241297      3\n",
       "[20]   0.0805288  0.243341      3\n",
       "[21]   0.0733749  0.245037      3\n",
       "[22]   0.0668565  0.246444      3\n",
       "[23]   0.0609171  0.247613      3\n",
       "[24]   0.0555054  0.248583      3\n",
       "[25]   0.0505745  0.249387      3\n",
       "[26]   0.0460816  0.250056      3\n",
       "[27]   0.0419878   0.25061      3\n",
       "[28]   0.0382577   0.25107      3\n",
       "[29]    0.034859  0.251453      3\n",
       "[30]   0.0317622   0.25177      3\n",
       "[31]   0.0289406  0.252033      3\n",
       "[32]   0.0263696  0.252252      3\n",
       "[33]    0.024027  0.252433      3\n",
       "[34]   0.0218925  0.252584      3\n",
       "[35]   0.0199476  0.252709      3\n",
       "[36]   0.0181755  0.252813      3\n",
       "[37]   0.0165609  0.252899      3\n",
       "[38]   0.0150896   0.25297      3\n",
       "[39]   0.0137491   0.25303      3\n",
       "[40]   0.0125277  0.253079      3\n",
       "[41]   0.0114148   0.25312      3\n",
       "[42]   0.0104007  0.253154      3\n",
       "[43]  0.00947673  0.253182      3\n",
       "[44]  0.00863484  0.253206      3\n",
       "[45]  0.00786775  0.253225      3\n",
       "[46]   0.0071688  0.253241      3\n",
       "[47]  0.00653194  0.253255      3\n",
       "[48]  0.00595166  0.253266      3\n",
       "[49]  0.00542293  0.253275      3\n",
       "], true, 100, 4, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = fit(DMRPaths, mf, covarsdf, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now select, for example the coefficients that minimize CV mse (takes a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       " -0.920603  -1.27898   -1.1979    -0.733303\n",
       " -3.22034   -1.61234   -0.368288   0.346255\n",
       " -2.15417   -1.65467    0.0        0.202824\n",
       " -2.04289   -0.857511  -0.329399   0.240294"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef(paths; select=:CVmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurdle Distributed Multiple Regression (HDMR)\n",
    "\n",
    "For highly sparse counts, as is often the case with text that is selected for\n",
    "various reasons, the Hurdle Distributed Multiple Regression (HDMR) model of\n",
    "Kelly, Manela, and Moreira (2018), may be superior to the DMR. It approximates\n",
    "a higher dispersion Multinomial using distributed (independent, parallel)\n",
    "Hurdle regressions, one for each of the d categories (columns) of a large `counts` matrix,\n",
    "on the `covars`. It allows a potentially different sets of covariates to explain\n",
    "category inclusion ($h=1{c>0}$), and repetition ($c>0$).\n",
    "\n",
    "Both the model for zeroes and for positive counts are regularized by default,\n",
    "using `GammaLassoPath`, picking the AICc optimal segment of the regularization\n",
    "path.\n",
    "\n",
    "HDMR can be fitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: fitting 100 observations on 4 categories \n",
      "│ 2 covariates for positive and 3 for zero counts\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/hdmr.jl:409\n",
      "┌ Info: distributed hurdle run on local cluster with 2 nodes\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/hdmr.jl:419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HDMRCoefs([-2.97869 -3.39104 -1.37637 -0.690629; 0.0 0.0 -0.724477 0.426105; 0.0 0.0 0.0 0.244869], [0.629667 -0.00316577 -0.521496 2.98134; -4.68583 -2.4084 0.0 0.0; -3.37301 -2.30744 0.0 0.0; -3.37706 -1.50431 0.0 0.0], true, 100, 4, 1:2, 1:3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = hdmr(covars, counts; inpos=1:2, inzero=1:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or with a dataframe and formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: fitting 100 observations on 4 categories \n",
      "│ 2 covariates for positive and 3 for zero counts\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/hdmr.jl:409\n",
      "┌ Info: distributed hurdle run on local cluster with 2 nodes\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/hdmr.jl:419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HDMRCoefs([-2.97869 -3.39104 -1.37637 -0.690629; 0.0 0.0 -0.724477 0.426105; 0.0 0.0 0.0 0.244869], [0.629667 -0.00316577 -0.521496 2.98134; -4.68583 -2.4084 0.0 0.0; -3.37301 -2.30744 0.0 0.0; -3.37706 -1.50431 0.0 0.0], true, 100, 4, [1, 2], [1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = @model(h ~ vy + v1 + v2, c ~ vy + v1)\n",
    "m = fit(HDMR, mf, covarsdf, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the h ~ equation is the model for zeros (hurdle crossing) and c ~ is the model for positive counts\n",
    "\n",
    "in either case we can get the coefficients matrix for each variable + intercept as usual with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-2.97869 -3.39104 -1.37637 -0.690629; 0.0 0.0 -0.724477 0.426105; 0.0 0.0 0.0 0.244869], [0.629667 -0.00316577 -0.521496 2.98134; -4.68583 -2.4084 0.0 0.0; -3.37301 -2.30744 0.0 0.0; -3.37706 -1.50431 0.0 0.0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefspos, coefszero = coef(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default we only return the AICc maximizing coefficients.\n",
    "To also get back the entire regulatrization paths, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: fitting 100 observations on 4 categories \n",
      "│ 2 covariates for positive and 3 for zero counts\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/hdmr.jl:289\n",
      "┌ Info: distributed hurdle run on remote cluster with 2 nodes\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/hdmr.jl:314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-2.97869 0.0 0.0; -2.93456 -0.15307 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0]\n",
       "\n",
       "[-3.39104 0.0 0.0; -3.29061 0.0 -0.251553; … ; -1.04786 -2.52399 -5.36357; -1.04459 -2.52915 -5.37187]\n",
       "\n",
       "[-1.68781 0.0 0.0; -1.65155 -0.0792342 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0]\n",
       "\n",
       "[-0.352618 0.0 0.0; -0.370878 0.037995 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0], [-3.87231 0.0 0.0 0.0; -3.72971 -0.30193 0.0 0.0; … ; 0.623512 -4.679 -3.36716 -3.37106; 0.629667 -4.68583 -3.37301 -3.37706]\n",
       "\n",
       "[-2.86015 0.0 0.0 0.0; -2.74269 -0.19503 -0.0481219 0.0; … ; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "\n",
       "[-0.521496 0.0 0.0 0.0; -0.448339 0.0 0.0 -0.13552; … ; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "\n",
       "[2.98134 0.0 0.0 0.0; 2.86604 0.0 0.248068 0.0; … ; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = fit(HDMRPaths, mf, covarsdf, counts)\n",
    "\n",
    "coef(paths; select=:all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sufficient reduction projection\n",
    "\n",
    "A sufficient reduction projection summarizes the counts, much like a sufficient\n",
    "statistic, and is useful for reducing the d dimensional counts in a potentially\n",
    "much lower dimension matrix `z`.\n",
    "\n",
    "To get a sufficient reduction projection in direction of vy for the above\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×3 Array{Float64,2}:\n",
       "  0.311047    0.0       10.0\n",
       "  0.311047    0.0       10.0\n",
       "  0.426105    0.0        3.0\n",
       " -0.260452   -0.802801   9.0\n",
       "  0.163324   -1.56194    6.0\n",
       "  0.261736    0.0        7.0\n",
       "  0.304361   -1.2042     7.0\n",
       " -0.0670014   0.0        7.0\n",
       "  0.426105    0.0        8.0\n",
       "  0.17042     0.0        9.0\n",
       "  0.298263    0.0        9.0\n",
       "  0.426105    0.0        4.0\n",
       "  0.13846     0.0        4.0\n",
       "  ⋮                         \n",
       " -0.119349   -1.56194    5.0\n",
       "  0.426105    0.0        4.0\n",
       " -0.149186    0.0        4.0\n",
       "  0.0923065  -0.802801   6.0\n",
       "  0.110768   -0.802801   5.0\n",
       "  0.13846     0.0        4.0\n",
       "  0.11231     0.0       11.0\n",
       "  0.0364953  -0.802801   7.0\n",
       " -0.0586262  -0.802801   8.0\n",
       "  0.426105    0.0        2.0\n",
       "  0.0923065  -1.77356    6.0\n",
       "  0.261736    0.0        7.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = srproj(m,counts,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first column is the SR projection from the model for positive counts, the second is the the SR projection from the model for hurdle crossing (zeros), and the third is the total count for each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts Inverse Regression (CIR)\n",
    "\n",
    "Counts inverse regression allows us to predict a covariate with the counts and other covariates.\n",
    "Here we use hdmr for the backward regression and another model for the forward regression.\n",
    "This can be accomplished with a single command, by fitting a CIR{HDMR,FM} where the forward model is FM <: RegressionModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: fitting 100 observations on 4 categories \n",
      "│ 2 covariates for positive and 3 for zero counts\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/hdmr.jl:409\n",
      "┌ Info: distributed hurdle run on local cluster with 2 nodes\n",
      "└ @ HurdleDMR /Users/root/.julia/packages/HurdleDMR/XuBHA/src/hdmr.jl:419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CIR{HDMR,LinearModel}(1, [1, 2], HDMRCoefs([-2.97869 -3.39104 -1.37637 -0.690629; 0.0 0.0 -0.724477 0.426105; 0.0 0.0 0.0 0.244869], [0.629667 -0.00316577 -0.521496 2.98134; -4.68583 -2.4084 0.0 0.0; -3.37301 -2.30744 0.0 0.0; -3.37706 -1.50431 0.0 0.0], true, 100, 4, [1, 2], [1, 2, 3]), LinearModel{LmResp{Array{Float64,1}},DensePredChol{Float64,Cholesky{Float64,Array{Float64,2}}}}:\n",
       "\n",
       "Coefficients:\n",
       "       Estimate Std.Error   t value Pr(>|t|)\n",
       "x1     0.596995  0.108965   5.47876    <1e-6\n",
       "x2    -0.165407 0.0953801  -1.73418   0.0862\n",
       "x3    -0.059985 0.0933614 -0.642503   0.5221\n",
       "x4     0.283205  0.126589   2.23721   0.0276\n",
       "x5     0.160959 0.0471665   3.41257   0.0010\n",
       "x6   0.00293183 0.0116717  0.251192   0.8022\n",
       "\n",
       ", LinearModel{LmResp{Array{Float64,1}},DensePredChol{Float64,Cholesky{Float64,Array{Float64,2}}}}:\n",
       "\n",
       "Coefficients:\n",
       "       Estimate Std.Error   t value Pr(>|t|)\n",
       "x1     0.456718 0.0713401   6.40198    <1e-8\n",
       "x2   -0.0414989 0.0975448 -0.425434   0.6715\n",
       "x3    0.0921372 0.0909831   1.01269   0.3137\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cir = fit(CIR{HDMR,LinearModel},mf,covarsdf,counts,:vy; nocounts=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the ```nocounts=true``` means we also fit a benchmark model without counts.\n",
    "\n",
    "we can get the forward and backward model coefficients with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-2.97869 -3.39104 -1.37637 -0.690629; 0.0 0.0 -0.724477 0.426105; 0.0 0.0 0.0 0.244869], [0.629667 -0.00316577 -0.521496 2.98134; -4.68583 -2.4084 0.0 0.0; -3.37301 -2.30744 0.0 0.0; -3.37706 -1.50431 0.0 0.0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefbwd(cir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Float64,1}:\n",
       "  0.5969947545574932   \n",
       " -0.16540667532095363  \n",
       " -0.05998499041491726  \n",
       "  0.28320494243822064  \n",
       "  0.16095913754958308  \n",
       "  0.0029318257220388305"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffwd(cir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model can be used to predict vy with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Union{Missing, Float64},1}:\n",
       " 0.545234930292324  \n",
       " 0.5325958888465925 \n",
       " 0.5677792380623129 \n",
       " 0.35305282642966895\n",
       " 0.32967807949439587\n",
       " 0.5241906269283231 \n",
       " 0.465096635838342  \n",
       " 0.4447192784387671 \n",
       " 0.5611672668012532 \n",
       " 0.5322351641015849 "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = predict(cir, covarsdf[1:10,:], counts[1:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict only with the other covariates, which in this case\n",
    "is just a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Union{Missing, Float64},1}:\n",
       " 0.45731660084749226\n",
       " 0.5179985510761541 \n",
       " 0.4807768729723196 \n",
       " 0.47254808567420575\n",
       " 0.47267552235044974\n",
       " 0.48519627697522144\n",
       " 0.4799151241219515 \n",
       " 0.44186379731084846\n",
       " 0.4592317510593359 \n",
       " 0.4232136851484049 "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_nocounts = predict(cir, covarsdf[1:10,:], counts[1:10,:]; nocounts=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelly, Manela, and Moreira (2018) show that the differences between DMR and HDMR can be substantial in some cases, especially when the counts data is highly sparse.\n",
    "\n",
    "Please reference the paper for additional details and example applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
